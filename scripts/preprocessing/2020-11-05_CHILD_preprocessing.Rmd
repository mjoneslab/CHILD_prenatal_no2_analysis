---
title: "CHILD data processing and normalization"
author: "SL"
date: "2020-10-22"
output: html_document
---

Load libraries needed for CHILD data.  
```{r libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(minfi)
library(wateRmelon)
library(sva)
library(ggpubr)
library(reshape2)
library(RColorBrewer)
library(here)
```


Read CHILD data in based on sample sheet provided - incorporates pData into rgset.  
In sample sheet C = cordblood and P = PMBCs.  
```{r import_data, message=FALSE, warning=FALSE}
#read in sample sheet for child data
sample_sheet <- read.metharray.sheet("R:/Jones/Projects/CHILD/CHILD raw data", pattern = ".csv$",
                                     recursive = FALSE, verbose = TRUE)

#change column names to what minfi expects
colnames(sample_sheet)[8] <- "Sentrix_ID"
colnames(sample_sheet)[9] <- "Sentrix_Position"

#one of the barcodes has a typo in sample sheet -> fix
sample_sheet[sample_sheet$Sentrix_ID == 9343114974, "Sentrix_ID"] <- 9343114074

#create a new column for basename - what read.metharray.exp looks for in targets is called
sample_sheet$Basename <- paste(sample_sheet$Sentrix_ID, 
                               sample_sheet$Sentrix_Position,
                               sep = "_") 

#add in sub directory
sample_sheet$Basename <- paste(sample_sheet$Sentrix_ID, 
                               sample_sheet$Basename,
                               sep = "/") 

#add in main directory
sample_sheet$Basename <- paste("R:/Jones/Projects/CHILD/CHILD raw data",
                               sample_sheet$Basename,
                               sep = "/") 

#read in meth array data
rgset <- read.metharray.exp(targets = sample_sheet, verbose=TRUE, extended = TRUE)
```

Assess quality of bisulfite conversion by examining probe intensities.
```{r bs_conversion_qc}
#type I probes
controlStripPlot(rgset, controls="BISULFITE CONVERSION I")

#type II probes
controlStripPlot(rgset, controls="BISULFITE CONVERSION II")
```


Remove bad probes based on detectionP value. Probes with at least one badDetP will be removed.  
```{r remove_bad_probes}
#samples with a (relatively) high proportion of bad probes should be removed

#fitler out probes with a detectionP value greater than  0.01
#requires RGSet 
badDetP <- detectionP(rgset)>0.01

#visual how many bad probes per sample
#first sum bad detP according to TRUE=1/FALSE=0 and put in data frame
nbaddetP_colsums <-as.data.frame(colSums(badDetP)) 
#add in sample_ID
nbaddetP_colsums$sample_id <- rgset$SampleID
#plot number of bad probes vs sample
ggplot(nbaddetP_colsums, aes(x=sample_id, y=colSums(badDetP))) +
  geom_col() +
  theme_classic() +
  labs(y="Number of failed probes") +
  rotate_y_text()

#find sample with large number of bad probes
nbaddetP_colsums$sample_id[nbaddetP_colsums$`colSums(badDetP)` == max(nbaddetP_colsums$`colSums(badDetP)`)]
  
#one sample (50602_C) has a higher number of failed probes than the rest
#remove before normalization
rgset_nobadsamp <- rgset[,!(rgset$SampleID=="50602_C")]

#check sizes
dim(rgset)
dim(rgset_nobadsamp)

#redo detP without bad sample
badDetP <- detectionP(rgset_nobadsamp)>0.01

#visual how many bad probes per sample
#first sum bad detP according to TRUE=1/FALSE=0 and put in data frame
nbaddetP_colsums <-as.data.frame(colSums(badDetP)) 
#add in sample_ID
nbaddetP_colsums$sample_id <-rgset_nobadsamp$SampleID
#plot in ggplot
ggplot(nbaddetP_colsums, aes(x=sample_id, y=colSums(badDetP))) +
  geom_col() +
  theme_classic() +
  labs(y="Number of failed probes") +
  rotate_x_text()

#visualize how many probes have 0,1,2, etc bad detectionP values
table(rowSums(badDetP))

#count number of probes with at least 1 bad detectionP 
nbadDetP_rowsums <-  sum(rowSums(badDetP)>=1)
nbadDetP_rowsums  #5043 probes have at least one badDetP value

#check  number of good probes
sum(rowSums(badDetP)==0)

#keep only good probes
ngoodDetP <- rowSums(badDetP)==0

#get list of cpgids with bad probes to remove
#these will be removed after preprocessing with noob and bmiq
detP_rm <- names(ngoodDetP[ngoodDetP==FALSE])
```


Get names of probes with less than 3 besa
```{r beads}
#using wateRmelon
#get bead count
beadcount <- beadcount(rgset_nobadsamp)

#get boolean matrix of failed  beads
bead_failed <- is.na(beadcount)

#get number of cpg probes with failed beads
sum(rowMeans(bead_failed)>0.01) #3954

bead_rm <- rownames(bead_failed)[rowMeans(bead_failed) > 0.01]
```

Combine list bad detP probes and probes with low bead count for removal after preprocessing/normalization
```{r badprobes}
#get combined list of all bad probes (without duplicates)
bad_probes <- union(detP_rm, bead_rm)

#get bad probe num
length(bad_probes) #8482
```


Save data with bad samples removed for cell type deconvolution. 
The estimateCellCounts2 function only accepts rgsets.   
```{r save_unprocessed_rgset}
#save(rgset_nobadsamp, 
#     file=here("output_data", "preprocessed_data", "2020-11-10_child_rgset_nobadsamp.Rdata"))
```

## Data preprocessing with Noob followed by BMIQ. 

Noob corrects for background using out-of-band probes (fluorescence of infinium 1 probes in opposite channel which they are designed for) and normalized-exponentional convolution. BMIQ is an intra-sample normalisation procedure, correcting the bias of type-2 probe values. BMIQ uses a 3-step procedure: (i) fitting of a 3-state beta mixture model, (ii) transformation of state-membership probabilities of type2 probes into quantiles of the type1 distribution, and (iii) a conformal transformation for the hemi-methylated probes

Normalize data using preprocessNoob - good for data where a large difference between groups is not expected.  
```{r noob}
#preprocessNoob
noob <- preprocessNoob(rgset_nobadsamp)

#bmiq normalization
bmiq <- BMIQ(noob)

#check that rows in all three are identical
identical(rownames(noob), rownames(bmiq)) #true
```

Map noob to genome for more qc and probe removal.
```{r maptogenome}
gmset <- mapToGenome(noob)
```

### Check for sample mix-ups based on predicted sex

Check for sample mix-ups based on sex.
```{r predicted_sex}
#add predicted sex to gmset
gmset <- addSex(gmset)

#plot based on predicted sex
plotSex(gmset)
```


### Bad probes, SN probes, XY probes, and cross reactive probes. 

Remove bad probes (detP or bead count), SNP probes, XY probes, and cross-reactive probes from noob. Then subset BMIQ rows for those in noob. The minfi function requires a genomic methyl set - cant use with BMIQ beta 

Remove bad probes.
```{r remove_badprobes}
#subset rows to exclude cpgids in bad probe list
gmset_nobadprobes <- gmset[!rownames(gmset) %in% bad_probes, ]

#check size
dim(gmset) #485512    298
dim(gmset_nobadprobes) #477030    298
# 8482 bad probes removed
```

Remove probes with SNPS  
```{r remove_snps}
#drop snps
gmset_no_badprobes_snps <- dropLociWithSnps(gmset_nobadprobes, snps = c("CpG"), maf = 0)

#create table of removed snps (should be all )
gmset_nosnpstable <- table(is.na(getSnpInfo(gmset_no_badprobes_snps)$CpG_rs))

#check size
dim(gmset_nobadprobes) #477030    298
dim(gmset_no_badprobes_snps) #461697    298
#remove  15333 probes

```

Remove XY probes.  
```{r remove_xy}
#drop x and y 
annotation=getAnnotation(gmset_no_badprobes_snps)

#check how many x and y probes are left
sum(annotation$chr %in% c("chrX","chrY"))
#10870 left

#get just probes that maps to autosomes
autosomes = annotation[!annotation$chr %in% c("chrX","chrY"), ]

#Remove XY
gmset_no_badprobes_snps_xy <- gmset_no_badprobes_snps[getAnnotation(gmset_no_badprobes_snps)[,4] %in% row.names(autosomes),]

#check that all x y probes are removed from set
sum(gmset_no_badprobes_snps_xy$chr %in% c("chrX","chrY")) # 0

#check size
dim(gmset_no_badprobes_snps) # 461697    298
dim(gmset_no_badprobes_snps_xy) #450827    298
#remove 10860 probes

#remove objects we no longer need
remove(annotation)
remove(autosomes)
```


Remove cross-reactive probes based on Chen 2013.    
```{r remove_cross_reactive_probes}
#read in cross-reactive probe info from Chen (2013) paper
cr_probes <- read.csv("R:/Jones/People/Samantha Lee/Computational/CHILD/input_data/chen-non-specific-probes-Illumina450k.csv", header=TRUE)

gmset_no_badprobes_snps_xy_cross <-  
  gmset_no_badprobes_snps_xy[!(rownames(gmset_no_badprobes_snps_xy) %in% cr_probes$TargetID), ] 

dim(gmset_no_badprobes_snps_xy) #450827    298
dim(gmset_no_badprobes_snps_xy_cross) #424644    298
#remove 26183 probes
```


Subset probes in BMIQ normalized data based on cleaned gmset data.
```{r bmiq_subset}
bmiq_clean <- bmiq[rownames(bmiq) %in% rownames(gmset_no_badprobes_snps_xy_cross), ]

#gmset_no_badprobes_snps_xy_crosscheck probe numbers - should be the same
dim(gmset_no_badprobes_snps_xy_cross) #424644    298
dim(bmiq_clean) #424644    298
```

## Subset out pdata, fdata, annotation

Get pdata and annotation  from preprocessed noob data
```{r get_methinfo}
#from noob
pdata <- pData(gmset_no_badprobes_snps_xy_cross)
annotation <- getAnnotation(gmset_no_badprobes_snps_xy_cross)

#save(beta, mvalue, pData, sampleNames, fData, annotated,
#     file = "R:/Jones/People/Samantha #Lee/Computational/CHILD/workspaces/2020-01-14_childnoob_beta_mvalue_pData_sampleNames_fData_ann#otated.RData")
```


## Quality control of CHILD data  

### MDS plot
MDS and PCA are both dimension reduction techniques but have different properties. 

PCA plots the original vectors in n-dimensional space. The data are projected onto the directions in the data with the most variance. Hence the “spread” of the data is roughly conserved as the dimensionality decreases.  

The input to MDS is the pairwise distances between points. The output of MDS is a two- or three-dimensional projection of the points where distances are preserved.  

Minfi's MDS plot calculates Euclidean distance between samples using the numPositions most variable CpG positions. These distances are then projected into a 2-d plane using classical multidimensional scaling transformation.  

Make MDS plot to examine data - part of QC.   
```{r mds_plot}
#do MDS plot manually based on code from minfi - allows plotting with ggplot

#using commands that mdsplot uses to calculate mds distances
beta_ordered <- order(rowVars(bmiq_clean), decreasing = TRUE)[seq_len(1000)] 
beta_ordered_dist <- dist(t(bmiq_clean[beta_ordered, ]))
beta_dist_naomit <- na.omit(beta_ordered_dist)
fit <- cmdscale(beta_dist_naomit)

#convert to dataframe for plotting
fit_df <- as.data.frame(fit)
#add in tissue information
fit_df$tissue <- pdata$Tissue
fit_df$samplename <- pdata$SampleID

#plot
mds <- ggplot(fit_df, aes(x=fit[,1], y=fit[,2])) + 
  geom_point(size=4, shape=21, alpha=0.7, aes(fill=tissue))+
  theme_classic() +
  labs(x="Distance 1", y="Distance 2", title = "Multidimensional scaling plot") 
  #ggrepel::geom_label_repel(data=fit_df, stat="identity", aes(label=samplename))

mds

#tissue mix up for sample 20113 -> relabel
pdata$SampleID[5] <- "20113_P"
pdata$Tissue[5] <- "P"
pdata$SampleID[6] <- "20113_C"
pdata$Tissue[6] <- "C"

#redo mds plot with relabelled samples
#using commands that mdsplot uses to calculate mds distances
beta_ordered <- order(rowVars(bmiq_clean), decreasing = TRUE)[seq_len(1000)] 
beta_ordered_dist <- dist(t(bmiq_clean[beta_ordered, ]))
beta_dist_naomit <- na.omit(beta_ordered_dist )
fit <- cmdscale(beta_dist_naomit)

#convert to dataframe for plotting
fit_df <- as.data.frame(fit)
#add in tissue information
fit_df$tissue <- pdata$Tissue
fit_df$samplename <- pdata$SampleID

#plot
mds2 <- ggplot(fit_df, aes(x=fit[,1], y=fit[,2])) + 
  geom_point(size=4, shape=21, alpha=0.7, aes(fill=tissue))+
  theme_classic() +
  labs(x="Distance 1", y="Distance 2", title = "Multidimensional scaling plot") 

mds2

rm(beta_dist_naomit, beta_ordered, beta_ordered_dist, fit, fit_df)
```

### Beta density plot

Examine beta density before and after normalization - part of QC

Beta density before normalization (but after bad probes removed)
```{r beta_density_before}
#before normalization
densityPlot(getBeta(rgset_nobadsamp))
```

Beta density after noob normalization, and after normalization with noob + bmiq
```{r beta_density_after}
#density plot after noob normalizatin
densityPlot(getBeta(noob))

#after normalization noob and bmiq normalization
density(bmiq)
#it's tighter now but there are still some methylated peaks with reduces height/slope
#left shifted methylatd peaks:20216_C, 20064_C, 20488_C, 30230_C, 30212_C, 50154_C
#no relation between left-shifted meth peaks and other participant features 
```

Beta density after nooob + bmiq normalization, and after removal of SNP, XY, and cross reactive probes. 
```{r beta_density_after_probe_removal}
densityPlot(getBeta(gmset_no_badprobes_snps_xy_cross))

#after bad probe removal, snp, xy, cross reactive probe removal of noob and bmiq preprocessed data
densityPlot(bmiq_clean)
```


### QC Plot  

Minfi's QC plot plots points as a function of the methylated and unmethylated values.  Points that have low methylated or unmethylated values will fall below QC cut off line (set at 10.5). This does not necessarily mean that samples are bad - futher investigation is needed to determine why these samples fall below the cut off line before determining if they should be discarded.  

Make QC plot - part of data QC.  
```{r qc_plot}
#use methyl or genomicmethyl data
#therefore must use data after noob but before bmiq normalization
#added na.omit, but may need to delete later
unmeth_medians <- log2(colMedians(na.omit(getUnmeth(noob))))
meth_medians <- log2(colMedians(na.omit(getMeth(noob))))
qc_data <- DataFrame(mMed = meth_medians, uMed = unmeth_medians)
rownames(qc_data) <- colnames(gmset_no_badprobes_snps_xy_cross)
qc_data <- as.data.frame(qc_data)
qc_data$Sample_ID <- pdata$Sample_ID
qc_data$tissue <- pdata$Tissue
qc_data$sex <- pdata$Sex
qc_data$chip <- pdata$Slide
qc_data$run <- pdata$Run

#can change badsamplecutoff
badSampleCutoff = 10.5
meds <- (qc_data$mMed + qc_data$uMed)/2
whichBad <- which((meds < badSampleCutoff))

#graph it
qcplot<- ggplot(qc_data, aes(x=mMed, y=uMed)) + 
  geom_point(size=4, shape=21, aes(fill=as.factor(run))) +
  labs(x="Methylated median", y="Unmethylated median", title="QC Plot") +
  geom_abline(intercept=badSampleCutoff * 2, slope=-1, linetype = "dashed") +
  theme_classic() 
#theme(legend.position="none") 
#run 1 is different from runb

qcplot
#samples from run number 2 fall below cut off line
#Run 2 has lower overall intensity because Meaghan and Julie (Mostly Meaghan) accidentally inverted some of the reagents in the staining step which affects the intensities values (as per correspondance with Illumina) -> samples are still good!. 
```

## Duplicate sample removal

Some cord blood samples had lots of DNA and were run with biological replicates. Plot the beta density to see if the replicates are similar, (and if so) then randomly choose which sample to choose.

```{r dup_sample_removal}
#samples with repeat measurements: 20367_C (4x), 40060_C (4x), 40083_C (4x)

#get rownums of 20367
dups <- grep("20367_C", pdata$SampleID)
#get rownames of 20367
dups_row <- rownames(pdata[dups,])

#density plot of 20367
densityPlot(bmiq_clean[, colnames(bmiq_clean) %in% dups_row], 
            sampGroups = colnames(bmiq_clean[, colnames(bmiq_clean) %in% dups_row]), legend = FALSE)



#################### SAMPLE SELECTION #######################

#these should have set.seed() so same sample always selected
#in this case selected sample is specified in code
#change in future

#select a ranomd sample from dups_row to include in analysis
sample(1:4, 1) #selected sample number 2 
dups_row[2] #use this sample in analysis: "9343114078_R06C01" (20367_C_Rep3_2)



#get rownums of 40060_C  
dups <- grep("40060_C", pdata$SampleID)
#get rownames of 40060_C  
dups_row <- rownames(pdata[dups,])

#density plot of 40060_C  
densityPlot(bmiq_clean[, colnames(bmiq_clean) %in% dups_row], 
            sampGroups = colnames(bmiq_clean[, colnames(bmiq_clean) %in% dups_row]), legend = FALSE)


#select a ranomd sample from dups_row to include in analysis
sample(1:4, 1) #select sample number 2 
dups_row[3] #use this sample in analysis: "9341679111_R02C02" (40060_C_Rep1_3)



#get rownums of 40083_C  
dups <- grep("40083_C", pdata$SampleID)
#get rownames of 40083_C  
dups_row <- rownames(pdata[dups,])

#density plot of 40083_C  
densityPlot(bmiq_clean[, colnames(bmiq_clean) %in% dups_row], 
            sampGroups = colnames(bmiq_clean[, colnames(bmiq_clean) %in% dups_row]), legend = FALSE)

#select a ranomd sample from dups_row to include in analysis
sample(1:4, 1) #select sample number 2 
dups_row[2] #use this sample in analysis: "9343114078_R05C01" (40083_C_Rep2_2)
```

Remove bad samples before batch correction as having multiple samples from same particpant may affect variance.  
```{r remove_dups}

#make list of samples to remove from beta and pData
dups_rm <-c("9298768102_R06C01", "9341679111_R05C02", "9298768023_R03C02",
            "9341679076_R06C02", "9297962089_R06C02", "9298768023_R02C02",
            "9341679097_R02C02", "9341679114_R01C02", "9298768023_R06C01")

#remove replicates from pdata                        
pdata_nodups <- pdata[!rownames(pdata) %in% dups_rm, ]
#check that 9 samples were removed
dim(pdata)
dim(pdata_nodups)


#remove replicates from beta matrix
bmiq_clean_nodups <- bmiq_clean[,!colnames(bmiq_clean) %in% dups_rm]
#check that 9 samples were removed
dim(bmiq_clean)
dim(bmiq_clean_nodups)
min(bmiq_clean_nodups)
max(bmiq_clean_nodups)
```

## Batch correciton

Heat Scree Plot and PCA heatmap function
```{r heat_scree_plot}
#initialize the heatplot function 
#outputs heatmap of PCs
#initialize the heatplot function 
#outputs heatmap of PCs
heat_scree_plot<-function(Loadings, Importance, Num, Order){

  ######### adjust according to importance of first PC #########
  adjust <- 1-Importance[1]
  pca_adjusted <- Importance[2:length(Importance)]/adjust
  pca_df <- data.frame(adjusted_variance = pca_adjusted, 
                      PC = seq(1:length(pca_adjusted)))
  
  ######### Scree plot #########
  
  #plot variance that each adjusted PC accounts for 
  scree <- ggplot(pca_df[which(pca_df$PC<=Num),],aes(PC,adjusted_variance)) + 
    geom_bar(stat = "identity",color="black",fill="grey") +
    theme_bw()+
    theme(axis.text = element_text(size =12),
          axis.title = element_text(size =15),
          plot.margin=unit(c(1,1.5,0.2,2.25),"cm"))+ylab("Variance") +
    scale_x_continuous(breaks = seq(1,Num,1))
  
  ######### Heat map of variance in each variable explained by PCs ######### 
  
  #correlate metadata (variables) with PCS
  #Run anova of each PC on each meta data variable
  
  ### Categorical variables ###
  
  #Run ANOVA on each PC
  aov_PC_meta <- lapply(1:ncol(meta_categorical), 
                        function(covar) sapply(1:ncol(Loadings), 
                        function(PC) summary(aov(Loadings[,PC]~
                                                 meta_categorical[,covar]))[[1]]$"Pr(>F)"[1]))
  
  #set names according to names of categorical variables
  names(aov_PC_meta) <- colnames(meta_categorical)
  #create matrix from list
  aov_PC_meta <- do.call(rbind, aov_PC_meta)
  
  
  ### Continuous variables ### 
  
  #Conduct spearman correlation 
  cor_PC_meta <- lapply(1:ncol(meta_continuous), 
                        function(covar) sapply(1:ncol(Loadings), 
                        function(PC) (cor.test(Loadings[,PC],
                                               as.numeric(meta_continuous[,covar]),
                                               alternative = "two.sided", method="spearman",
                                               na.action=na.omit, exact=FALSE)$p.value)))
  
  #rename according to names of continuous variables
  names(cor_PC_meta)<-colnames(meta_continuous)
  #create matrix from list
  cor_PC_meta<-do.call(rbind, cor_PC_meta)
  
  
  ### Prepare continous and categorical data for heat map ###
  
  #combine as df
  allvar_PC <- as.data.frame(rbind(aov_PC_meta, cor_PC_meta))
  
  #omit first pc to adjust
  allvar_PC_adjust <- allvar_PC[,2:ncol(allvar_PC)]
  
  ### Clean all variable PCs for plotting ###
  
  #plot number of PCs specified by user 
  #reduces number of columns to be equal to "num"
  plotting_PCs <- allvar_PC_adjust[,1:Num]
  
  #convert plotting PCs to numeric
  plotting_PCs_num <- apply(plotting_PCs,2, as.numeric)
  
  #convert plotting PCs to dataframe
  plotting_PCs_num <- as.data.frame(plotting_PCs_num)
  
  #Rename columna to PC 1, 2, 3, etc...
  colnames(plotting_PCs_num) <- sapply(1:Num, function(x) paste("PC",x, sep=""))
  
  #Create column to name rows accordiong to variable names (metadata)
  plotting_PCs_num$meta <- rownames(plotting_PCs[1:nrow(plotting_PCs),])
  
  #Melt dataframe to long format for plotting
  plotting_PCs_melt <- reshape2::melt(plotting_PCs_num, id.vars="meta")
  
  #Cluster metadata according to order specified by user
  ord <- Order
  plotting_PCs_order <- unique(plotting_PCs_melt$meta)[rev(ord)]
  plotting_PCs_melt$meta <- factor(plotting_PCs_melt$meta, levels = plotting_PCs_order)
  
  #hard code colours for heat map into dataframe according to PC significance
  plotting_PCs_melt$Pvalue<-sapply(1:nrow(plotting_PCs_melt), function(x)
    if(plotting_PCs_melt$value[x]<=0.001){"<=0.001"}else{
      if(plotting_PCs_melt$value[x]<=0.01){"<=0.01"}else{
        if(plotting_PCs_melt$value[x]<=0.05){"<=0.05"}else{">0.05"}}})
  
  heat <- ggplot(plotting_PCs_melt, aes(variable, meta, fill = Pvalue)) +
    geom_tile(color = "black",size=0.5) +
    theme_gray(8) + 
    scale_fill_manual(breaks = c("<=0.001", "<=0.01", "<=0.05", ">0.05"),
                        values=c("#084594","#4292c6","#9ecae1","#ffffff")) + 
    theme(axis.text = element_text(size =10, color="black"),
          axis.text.x = element_text(),
          axis.title = element_text(size =15),
          legend.text = element_text(size =14),
          legend.title = element_text(size =12),
          legend.position = "bottom",
          plot.margin=unit(c(0,2.25,1,1),"cm"))+
    xlab("Principal Component")+ylab(NULL)
  
  cowplot::plot_grid(scree, heat, ncol=1)
}

```

### Batch correction of CHILD DNAm data

Create m-values based on noob + bmiq normalized beta values
```{r mvalues}
mvals <- beta2m(bmiq_clean_nodups)

max(mvals)
min(mvals)

max(bmiq_clean_nodups)
min(bmiq_clean_nodups)

#rename for simplicity
#betas <- bmiq_clean_nodups
```

Make model matrix for batch correction. This invovles changing pData columns to factors as they are categorical not continuous. Because we are not correcting for covariates the model matrix will simply be the intercept. 
```{r model_matrix}
pdata_nodups$Run <- as.factor(pdata_nodups$Run)
pdata_nodups$Sentrix_ID <- as.factor(pdata_nodups$Sentrix_ID)
#pull out row from sentrix position then set to factor
pdata_nodups$row <- substr(pdata_nodups$Sentrix_Position, 1, 3)
pdata_nodups$row <- factor(pdata_nodups$row, ordered=T)
pdata_nodups$row <- as.numeric(pdata_nodups$row)
pdata_nodups$Sex <- as.factor(pdata_nodups$Sex)
pdata_nodups$Group <- as.factor(pdata_nodups$Group)
pdata_nodups$Atopy <- as.factor(pdata_nodups$Atopy)
pdata_nodups$Wheeze <- as.factor(pdata_nodups$Wheeze)
pdata_nodups$Tissue <- as.factor(pdata_nodups$Tissue)

#run batch correction in the order of (1) run, (2) row, (chip)

#create a model matrix using pdata
#this generates intercepts only since we are not adding in covariates
mod = model.matrix(~1, data=pdata_nodups)
```

Examine heat scree plot before any batch correction.  
```{r heat_scree_before}
uncor.dat <- t(scale(t(mvals)))
PCA_full<-princomp(na.omit(uncor.dat))
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance<-vars/sum(vars)

#Specify which covariates are categorical and/or continuous
#only have categorical
meta_categorical <- pdata_nodups[,c("Run", "Sentrix_ID" ,"Sex", "Group", "Atopy", "Wheeze", "Tissue")] 

meta_continuous <- pdata_nodups[,c("row")]

# Specify the number of PCs you want shown 
# pick enough to view most of the variance
Num<-10

# Designate what order you want the variables to appear (continuous variables rbinded to categorical variables in function)
Order<-c(1:10)

#Apply function on PCA results of uncorrected data, pulls in the meta data and beta values from above
heat_scree_plot(Loadings, Importance, Num, Order)
```

#Batch correction should be done in the following order: (1) run, (2) row, then (3) chip.

Batch correction for chip:
```{r batch_chip}
#can't have NAs for this function -> already removed them
combat_run <- ComBat(dat=mvals, batch=pdata_nodups$Run, mod = mod) 

#PCA
uncor.dat <- t(scale(t(combat_run)))
PCA_full<-princomp(na.omit(uncor.dat))
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance<-vars/sum(vars)

# Specify the number of PCs you want shown 
# pick enough to view most of the variance
Num<-10

# Designate what order you want the variables to appear (continuous variables rbinded to categorical variables in function)
Order<-c(1:10)

#Apply function on PCA results of uncorrected data, pulls in the meta data and beta values from above
meta_categorical<-pdata_nodups[,c("Run", "Sentrix_ID","Sex", "Group", "Atopy", "Wheeze", "Tissue")] 


meta_continuous <- as.data.frame(pdata_nodups[,c("row")])


heat_scree_plot(Loadings, Importance, Num, Order)

```


Batch correction for row:
```{r batch_row}
#can't have NAs for this function -> already removed them
combat_row <- ComBat(dat=combat_run, batch=pdata_nodups$row, mod = mod) 

#PCA
uncor.dat <- t(scale(t(combat_row)))
PCA_full<-princomp(na.omit(uncor.dat))
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance<-vars/sum(vars)

# Specify the number of PCs you want shown 
# pick enough to view most of the variance
Num<-10

# Designate what order you want the variables to appear (continuous variables rbinded to categorical variables in function)
Order<-c(1:10)

#Apply function on PCA results of uncorrected data, pulls in the meta data and beta values from above
meta_categorical<-pdata_nodups[,c("Run", "Sentrix_ID" ,"Sex", "Group", "Atopy", "Wheeze", "Tissue")] 

meta_continuous <- as.data.frame(pdata_nodups[,c("row")])

heat_scree_plot(Loadings, Importance, Num, Order)
```




meta_continuous <- pdata_nodups[,c("row")]Convert to betas
```{r beats}
betas_batchcorr <- lumi::m2beta(combat_row)
min(betas_batchcorr) 
max(betas_batchcorr) 

```

```{r savedata}
#save mvalues, pdata, and annotation
save(betas_batchcorr, pdata_nodups, annotation,
     file=here("output_data", "preprocessed_data", "2020-11_24_CHILD_preprocessed_betas_batchrunrow_pdata_annotation.Rdata"))

```





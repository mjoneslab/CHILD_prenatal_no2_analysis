---
title: "CHILD CBMC cell types vs PCs correction "
author: "SL"
date: "January 19, 2021"
output: html_document
---

IMPORTANT: This code is for cell type correction before linear models for EWAS. The other option is to include cell type proportions in EWAS linear models. 

```{r libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(minfi)
library(pbapply)
library(limma)
library(rgr) #for log centred ratio transfromation
library(factoextra)
library(GGally)
library(here)
```

Load preprocessed CHILD data.  
```{r load_betas, message=FALSE, warning=FALSE}
load("R:/Jones/People/Samantha Lee/Projects/CHILD/CHILD_air_pollution/output_data/preprocessed_data/2021-01_14_CHILD_preprocessed_betas_pdata_annotation.Rdata")
```

Load CHILD deconvolution data. This deconvolution does not include granulocytes as granulocytes are not expected.
```{r load_deconvolution, message=FALSE, warning=FALSE}
load(here("output_data", "deconvolution", "2020-11-10_CBMC_PBMC_deconvolution.RData"))

#only want to keep child_fscbc_ecc2_cb
rm(child_fscbc_ecc2_y1)
```


Remove duplicates from cord blood deconvolution data.  
```{r remove_dups_from_deconvo}
#convert deconvolution data to dataframe
child_fscbc_ecc2_cb_df <- as.data.frame(child_fscbc_ecc2_cb$counts)

#make list of samples to remove from beta and pData
dups_rm <-c("9298768102_R06C01", "9341679111_R05C02", "9298768023_R03C02",
            "9341679076_R06C02", "9297962089_R06C02", "9298768023_R02C02",
            "9341679097_R02C02", "9341679114_R01C02", "9298768023_R06C01")

#remove replicates from cell type estimates                      
child_fscbc_ecc2_cb_df_nodups <-
  child_fscbc_ecc2_cb_df[!rownames(child_fscbc_ecc2_cb_df) %in% dups_rm, ]

#check that 9 samples were removed
dim(child_fscbc_ecc2_cb_df_nodups)
dim(child_fscbc_ecc2_cb_df)
```


## CBMC data prepartion for cell type correction 

Subset out age one m-values for cell type correction.  
```{r subset_age1_mvals}
#subset out cordblood samples from beta matrix
cb_betas <- betas[,colnames(betas) %in% rownames(subset(pdata_nodups, Tissue == "C"))]

#check size of mval matrix after subsetting
dim(cb_betas) #144
min(cb_betas) # 0.003159977
max(cb_betas) # 0.9980158

```


## Cell type correction

Correct age one PBMCs for cell type using linear regression. 

Based on "Adjusting for cell type composition in DNA methylation data using a regression-based approach" by Jones et al (2017).  

The data is composite data and cell types are not independent of one another:  

Two ways of dealing with this:  

1. Do a PCA  
* variables are not independent -PCA will give all the same data but in independent vectors  
* But cant do PCA on composite data - this is composite data  
* Do a centred log ratio before PCA to get around this  

2. Leave out one cell type  
* More simple way  
* Usually leave cell type that is largest proportion  
* For whole blood/cord blood - drop granulocytes  
* For PMBCs and CBMCs - drop CD4T cells  


Cell type correction
```{r cordblood_celltype_correction}
#fit a linear model for each probe in the matrix
#no granulocytes
#drop cd4t

#fit a linear model for each probe in the matrix using cell type PCs as covariates
cb_celltype_design <- model.matrix(~ NK + nRBC + Bcell + Mono + CD8T ,
                              data=child_fscbc_ecc2_cb_df_nodups)

#fit methylation to batch variables then get residuals
cb_celltype_fit <-  lmFit(cb_betas, cb_celltype_design)

#get residuals 
cb_celltype_residuals <- residuals(cb_celltype_fit, cb_betas) 

#check if colnames of cordblood residuals and cord blood batch corrected betas are the same
identical(colnames(cb_celltype_residuals), colnames(cb_betas))

#add residuals of each regression model to the mean methyaltion value of each probe (mean across samples)
#this gives the "corrected" methylation data
celltype_adj_betas <- cb_celltype_residuals + matrix(apply(cb_betas, 1, mean), 
                                     nrow=nrow(cb_celltype_residuals), 
                                     ncol=ncol(cb_celltype_residuals))


#check how unadjusted and adjusted betas compares
#batch corrected
print(cb_betas[1:5,1:5])
#cell type PC adjusted
print(celltype_adj_betas[1:5,1:5])
```


Adjust beta values so that values >1 or <0 are now equal to largest number below 1 and smallest number below 0, respectively. 
```{r adjust_beta_range}
#check that adjusted betas do not fall below 0 or above 1
max(celltype_adj_betas) # 1.162851 
min(celltype_adj_betas) # -0.2477386

# adj.betas contains values less than 0 and greater than 1 
# These need to be fixed because they result in NAs during conversion to M values
# Replace values higher than 1 with the largest number closest to 1
# Replace values lower than 0 with the lowest non-negative number
message("Setting floor to lowest measurement above 0,\n",
        "and ceiling to highest measurement below 1 for M value conversion")
celltype_adj_betas[celltype_adj_betas > 1] <- max(celltype_adj_betas[celltype_adj_betas < 1])
celltype_adj_betas[celltype_adj_betas < 0] <- min(celltype_adj_betas[celltype_adj_betas > 0])

#check that adjusted betas do not fall below 0 or above 1
max(celltype_adj_betas) # 0.9999994
min(celltype_adj_betas) # 0.9999994-07

```


Convert cell type corrected beta values back to m-values for further statistical analysis.  
```{r beta2m}
#convert beta values to m values
celltype_adj_mvals <- lumi::beta2m(celltype_adj_betas)

#check max/min of mvals
max(celltype_adj_mvals)
min(celltype_adj_mvals)
```


## Now with PCs

Centred log ratio wont accept negative values. Additionally, centred log ratio will accept zeros however rows with 0s will return NA for 0 instance and infinity for all othe values. Therefore check for any negative values as well as 0s. If there are zeroes or negatives need to investigate why.
```{r remove_neg_values}
#check how many negatives
sum(child_fscbc_ecc2_cb_df_nodups <= 0) #0
```

Centred log ratio of estimated cell type proportions.
```{r clr}
cb_celltypes_clr <- clr(as.matrix(child_fscbc_ecc2_cb_df_nodups))

#check for NAs or inf
#these will occur if zeroes or negatives existed in cell tyoe estimates
sum(is.na(cb_celltypes_clr)) #0
sum(is.infinite(cb_celltypes_clr)) #0
```

Run PCA analysis on CLR transformed cell type estimates
```{r celltype_pca}
#pca
cb_pca <- prcomp(cb_celltypes_clr, scale. = TRUE)

#scree plot
factoextra::fviz_eig(cb_pca)

#convert to dataframe
cb_pcs <- as.data.frame(cb_pca$x)
#correct based on first 5 PCs

#examine grouping of pcs
ggpairs(cb_pcs, columns=1:6, progress=FALSE)  
```


Cell type correction using the first 6 cell type PCs. 
```{r cordblood_6PC_correction}
#fit a linear model for each probe in the matrix using cell type PCs as covariates
cb_pcs_design <- model.matrix(~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6, data=cb_pcs)

#fit methylation to batch variables then get residuals
cb_pcs_fit <-  lmFit(cb_betas, cb_pcs_design)

#get residuals 
cb_pcs_residuals <- residuals(cb_pcs_fit, cb_betas) 

#check if colnames of cordblood residuals and cord blood batch corrected betas are the same
identical(colnames(cb_pcs_residuals), colnames(cb_betas))

#add residuals of each regression model to the mean methyaltion value of each probe (mean across samples)
#this gives the "corrected" methylation data
pc_adj_betas <- cb_pcs_residuals + matrix(apply(cb_betas, 1, mean), 
                                     nrow=nrow(cb_pcs_residuals), 
                                     ncol=ncol(cb_pcs_residuals))


#check how unadjusted and adjusted betas compares
#batch corrected
print(cb_betas[1:5,1:5])
#cell type PC adjusted
print(pc_adj_betas[1:5,1:5])
```



Adjust beta values so that values >1 or <0 are now equal to largest number below 1 and smallest number below 0, respectively. 
```{r adjust_beta_range}
#check that adjusted betas do not fall below 0 or above 1
max(pc_adj_betas) #1.182634
min(pc_adj_betas) #-0.1585874

# PC adjusted betas contains values less than 0 and greater than 1 
# Replace values higher than 1 with the largest number closest to 1
# Replace values lower than 0 with the lowest non-negative number
pc_adj_betas[pc_adj_betas > 1] <- max(pc_adj_betas[pc_adj_betas < 1])
pc_adj_betas[pc_adj_betas < 0] <- min(pc_adj_betas[pc_adj_betas > 0])

#check that adjusted betas do not fall below 0 or above 1
max(pc_adj_betas) # 0.9999994
min(pc_adj_betas) # 8.904845e-06
```

Convert cell type corrected beta values back to m-values for further statistical analysis.  
```{r beta2m}
#convert beta values to m values
pc_adj_mvals <- lumi::beta2m(pc_adj_betas)

#check max/min of mvals
max(pc_adj_mvals)
min(pc_adj_mvals)
```

Cell type correction using the first 5 cell type PCs. 
```{r cordblood_5PC_correction}
#fit a linear model for each probe in the matrix using cell type PCs as covariates
cb_5pcs_design <- model.matrix(~ PC1 + PC2 + PC3 + PC4 + PC5, data=cb_pcs)

#fit methylation to batch variables then get residuals
cb_5pcs_fit <-  lmFit(cb_betas, cb_5pcs_design)

#get residuals 
cb_5pcs_residuals <- residuals(cb_5pcs_fit, cb_betas) 

#check if colnames of cordblood residuals and cord blood batch corrected betas are the same
identical(colnames(cb_5pcs_residuals), colnames(cb_betas))

#add residuals of each regression model to the mean methyaltion value of each probe (mean across samples)
#this gives the "corrected" methylation data
pc5_adj_betas <- cb_5pcs_residuals + matrix(apply(cb_betas, 1, mean), 
                                     nrow=nrow(cb_5pcs_residuals), 
                                     ncol=ncol(cb_5pcs_residuals))


#check how unadjusted and adjusted betas compares
#batch corrected
print(cb_betas[1:5,1:5])
#cell type PC adjusted
print(pc5_adj_betas[1:5,1:5])
```



Adjust beta values so that values >1 or <0 are now equal to largest number below 1 and smallest number below 0, respectively. 
```{r adjust_beta_range}
#check that adjusted betas do not fall below 0 or above 1
max(pc5_adj_betas) #1.182634
min(pc5_adj_betas) #-0.1585874

# PC adjusted betas contains values less than 0 and greater than 1 
# Replace values higher than 1 with the largest number closest to 1
# Replace values lower than 0 with the lowest non-negative number
pc5_adj_betas[pc5_adj_betas > 1] <- max(pc5_adj_betas[pc5_adj_betas < 1])
pc5_adj_betas[pc5_adj_betas < 0] <- min(pc5_adj_betas[pc5_adj_betas > 0])

#check that adjusted betas do not fall below 0 or above 1
max(pc5_adj_betas) # 0.9999994
min(pc5_adj_betas) # 8.904845e-06
```

Convert cell type corrected beta values back to m-values for further statistical analysis.  
```{r beta2m}
#convert beta values to m values
pc5_adj_mvals <- lumi::beta2m(pc5_adj_betas)

#check max/min of mvals
max(pc5_adj_mvals)
min(pc5_adj_mvals)
```






### Heat scree plots for comparing correction efficiency


Set up heat scree plot function
```{r heat_plot}

#initialize the heatplot function 
#outputs heatmap of PCs
heat_scree_plot <- function(Loadings, Importance, Num, Order){

  ######### adjust according to importance of first PC #########
  adjust <- 1-Importance[1]
  pca_adjusted <- Importance[2:length(Importance)]/adjust
  pca_df <- data.frame(adjusted_variance = pca_adjusted, 
                      PC = seq(1:length(pca_adjusted)))
  
  ######### Scree plot #########
  
  #plot variance that each adjusted PC accounts for 
  scree <- ggplot(pca_df[which(pca_df$PC<=Num),],aes(PC,adjusted_variance)) + 
    geom_bar(stat = "identity",color="black",fill="grey") +
    theme_bw()+
    theme(axis.text = element_text(size =12),
          axis.title = element_text(size =15),
          plot.margin=unit(c(1,1.5,0.2,2.25),"cm"))+ylab("Variance") +
    scale_x_continuous(breaks = seq(1,Num,1))
  
  ######### Heat map of variance in each variable explained by PCs ######### 
  
  #correlate metadata (variables) with PCS
  #Run anova of each PC on each meta data variable
  
  ### Categorical variables ###
  
  #Run ANOVA on each PC
  aov_PC_meta <- lapply(1:ncol(meta_categorical), 
                        function(covar) sapply(1:ncol(Loadings), 
                        function(PC) summary(aov(Loadings[,PC]~
                                                 meta_categorical[,covar]))[[1]]$"Pr(>F)"[1]))
  
  #set names according to names of categorical variables
  names(aov_PC_meta) <- colnames(meta_categorical)
  #create matrix from list
  aov_PC_meta <- do.call(rbind, aov_PC_meta)
  
  
  ### Continuous variables ### 
  
  #Conduct spearman correlation 
  cor_PC_meta <- lapply(1:ncol(meta_continuous), 
                        function(covar) sapply(1:ncol(Loadings), 
                        function(PC) (cor.test(Loadings[,PC],
                                               as.numeric(meta_continuous[,covar]),
                                               alternative = "two.sided", method="spearman",
                                               na.action=na.omit, exact=FALSE)$p.value)))
  
  #rename according to names of continuous variables
  names(cor_PC_meta)<-colnames(meta_continuous)
  #create matrix from list
  cor_PC_meta<-do.call(rbind, cor_PC_meta)
  
  
  ### Prepare continous and categorical data for heat map ###
  
  #combine as df
  allvar_PC <- as.data.frame(rbind(aov_PC_meta, cor_PC_meta))
  
  #omit first pc to adjust
  allvar_PC_adjust <- allvar_PC[,2:ncol(allvar_PC)]
  
  ### Clean all variable PCs for plotting ###
  
  #plot number of PCs specified by user 
  #reduces number of columns to be equal to "num"
  plotting_PCs <- allvar_PC_adjust[,1:Num]
  
  #convert plotting PCs to numeric
  plotting_PCs_num <- apply(plotting_PCs,2, as.numeric)
  
  #convert plotting PCs to dataframe
  plotting_PCs_num <- as.data.frame(plotting_PCs_num)
  
  #Rename columna to PC 1, 2, 3, etc...
  colnames(plotting_PCs_num) <- sapply(1:Num, function(x) paste("PC",x, sep=""))
  
  #Rename rownames accordiong to variable names (metadata)
  plotting_PCs_num$meta <- rownames(plotting_PCs[1:nrow(plotting_PCs),])
  
  #Melt dataframe to long format for plotting
  plotting_PCs_melt <- reshape2::melt(plotting_PCs_num, id.vars="meta")
  
  #Cluster metadata according to order specified by user
  ord <- Order
  plotting_PCs_order <- unique(plotting_PCs_melt$meta)[rev(ord)]
  plotting_PCs_melt$meta <- factor(plotting_PCs_melt$meta, levels = plotting_PCs_order)
  
  #hard code colours for heat map into dataframe according to PC significance
  plotting_PCs_melt$Pvalue<-sapply(1:nrow(plotting_PCs_melt), function(x)
    if(plotting_PCs_melt$value[x]<=0.001){"<=0.001"}else{
      if(plotting_PCs_melt$value[x]<=0.01){"<=0.01"}else{
        if(plotting_PCs_melt$value[x]<=0.05){"<=0.05"}else{">0.05"}}})
  
  heat <- ggplot(plotting_PCs_melt, aes(variable, meta, fill = Pvalue)) +
    geom_tile(color = "black",size=0.5) +
    theme_gray(8) + 
    scale_fill_manual(breaks = c("<=0.001", "<=0.01", "<=0.05", ">0.05"),
                        values=c("#084594","#4292c6","#9ecae1","#ffffff")) + 
    theme(axis.text = element_text(size =10, color="black"),
          axis.text.x = element_text(),
          axis.title = element_text(size =15),
          legend.text = element_text(size =14),
          legend.title = element_text(size =12),
          legend.position = "bottom",
          plot.margin=unit(c(0,2.25,1,1),"cm"))+
    xlab("Principal Component")+ylab(NULL)
  
  cowplot::plot_grid(scree, heat, ncol=1)
}

```



```{r model_matrix_age1}
#subset out cordblood meta data 
cb_pdata <- as.data.frame(subset(pdata_nodups, Tissue == "C"))

#change categorical variables to factors
cb_pdata$Run <- as.factor(cb_pdata$Run)
cb_pdata$Chip <- as.factor(cb_pdata$Sentrix_ID)
#pull out row from sentrix position then set to factor
cb_pdata$Row <- substr(cb_pdata$Sentrix_Position, 1, 3)
cb_pdata$Row <- as.factor(cb_pdata$Row)
cb_pdata$Row <- as.numeric(cb_pdata$Row)
cb_pdata$Sex <- as.factor(cb_pdata$Sex)
cb_pdata$Group <- as.factor(cb_pdata$Group)
cb_pdata$Atopy <- as.factor(cb_pdata$Atopy)
cb_pdata$Wheeze <- as.factor(cb_pdata$Wheeze)

#check to see if samples are in same order between pData and and betas
identical(rownames(cb_pdata), rownames(child_fscbc_ecc2_cb_df_nodups))
#bind columns together for one large metadata frame
cb_pdata <- cbind(cb_pdata, child_fscbc_ecc2_cb_df_nodups)


#create a model matrix using pData
#this generates intercepts only since we are not adding in covariates
mod = model.matrix(~1, data=cb_pdata)
```

```{r heatscree_before}
#convert raw betas to mvals
cb_mvals <- lumi::beta2m(cb_betas)
max(cb_mvals)
min(cb_mvals)

#pca 
uncor.dat <- t(scale(t(cb_mvals)))
PCA_full<-princomp(na.omit(uncor.dat))
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance <-vars/sum(vars)

#Specify which covariates are categorical and/or continuous
meta_categorical <- cb_pdata[,c("Sex", "Group", "Run", "Chip")] 
meta_continuous <- cb_pdata[,c("nRBC" ,"NK", "Bcell", "Mono", "CD8T", "CD4T", "Row")]

# Specify the number of PCs you want shown 
# pick enough to view most of the variance
Num<-11

# Designate what order you want the variables to appear (continuous variables rbinded to categorical variables in function)
Order<-c(1:11)

#Apply function on PCA results of uncorrected data, pulls in the meta data and beta values from above
heat_scree_plot(Loadings, Importance, Num, Order)
```

PCs after cell type correction
```{r heatscree_celltype}
#pca 
uncor.dat <- t(scale(t(celltype_adj_mvals)))
PCA_full<-princomp(na.omit(uncor.dat))
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance <-vars/sum(vars)

#Specify which covariates are categorical and/or continuous
meta_categorical <- cb_pdata[,c("Sex", "Group", "Run", "Chip")] 
meta_continuous <- cb_pdata[,c("nRBC" ,"NK", "Bcell", "Mono", "CD8T", "CD4T", "Row")]

# Specify the number of PCs you want shown 
# pick enough to view most of the variance
Num<-11

# Designate what order you want the variables to appear (continuous variables rbinded to categorical variables in function)
Order<-c(1:11)

#Apply function on PCA results of uncorrected data, pulls in the meta data and beta values from above
heat_scree_plot(Loadings, Importance, Num, Order)
```

PCs after 6 PC correction
```{r heatscree_pc}
#pca 
uncor.dat <- t(scale(t(pc_adj_mvals)))
PCA_full<-princomp(na.omit(uncor.dat))
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance <-vars/sum(vars)

#Specify which covariates are categorical and/or continuous
meta_categorical <- cb_pdata[,c("Sex", "Group", "Run", "Chip")] 
meta_continuous <- cb_pdata[,c("nRBC" ,"NK", "Bcell", "Mono", "CD8T", "CD4T", "Row")]

# Specify the number of PCs you want shown 
# pick enough to view most of the variance
Num<-11

# Designate what order you want the variables to appear (continuous variables rbinded to categorical variables in function)
Order<-c(1:11)

#Apply function on PCA results of uncorrected data, pulls in the meta data and beta values from above
heat_scree_plot(Loadings, Importance, Num, Order)
```

PCs after 5 PC correction
```{r heatscree_5pc}
#pca 
uncor.dat <- t(scale(t(pc5_adj_mvals)))
PCA_full<-princomp(na.omit(uncor.dat))
Loadings<-as.data.frame(unclass(PCA_full$loadings))
vars <- PCA_full$sdev^2
Importance <-vars/sum(vars)

#Specify which covariates are categorical and/or continuous
meta_categorical <- cb_pdata[,c("Sex", "Group", "Run", "Chip")] 
meta_continuous <- cb_pdata[,c("nRBC" ,"NK", "Bcell", "Mono", "CD8T", "CD4T", "Row")]

# Specify the number of PCs you want shown 
# pick enough to view most of the variance
Num<-11

# Designate what order you want the variables to appear (continuous variables rbinded to categorical variables in function)
Order<-c(1:11)

#Apply function on PCA results of uncorrected data, pulls in the meta data and beta values from above
heat_scree_plot(Loadings, Importance, Num, Order)
```


